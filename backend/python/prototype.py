# -*- coding: utf-8 -*-
"""prototype.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lpH2kpkj9sf0ViO85FrVN8n0zsvERcWi
"""

!pip install -q transformers[torch]

"""
# Setiment analysis example"""

from transformers import AutoModel, AutoTokenizer

checkpoint = "Hyeonseo/ko-finance_news_classifier"
model = AutoModel.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

text = "카카오뱅크와 에프엔가이드가 금융특화 언어모델을 공개합니다."
tokens = tokenizer.tokenize(text)
print(tokens)

inputs = tokenizer(text, return_tensors="pt")
model_output = model(**inputs)
print(model_output)

"""## sentiment analysis pipeline"""

from transformers import pipeline

classifier = pipeline("sentiment-analysis", model=checkpoint)
classifier(
    [
        "신세계백화점이 지난해 역대 최대 매출을 올렸다.",
        "국내 최대 컨테이너 선사인 HMM 매각 협상이 6일 최종 결렬되면서 산업은행이 고심에 빠졌다.",
        "카카오뱅크와 에프엔가이드가 금융특화 언어모델을 공개합니다.",
    ]
)

"""부정/긍정/중립 출력확인

#Keyword extraction
"""

from transformers import AutoTokenizer, AutoModelForTokenClassification
from transformers import pipeline

tokenizer = AutoTokenizer.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
model = AutoModelForTokenClassification.from_pretrained("Leo97/KoELECTRA-small-v3-modu-ner")
ner = pipeline("ner", model=model, tokenizer=tokenizer)
# pipeline
example = "서울역으로 안내해줘."
ner_results = ner(example)
print(ner_results)

type(ner_results)

"""회사명만 추출, H는 HMM 앞글자만 나옴"""

ner_results = ner(raw_inputs)
og = []
for result in ner_results:
    og.append(result['entity'in ['B-OG']])

og

